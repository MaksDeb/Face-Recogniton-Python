{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def load_images_and_labels(base_dir, class_labels):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label, folder_name in class_labels.items():\n",
        "        folder_path = os.path.join(base_dir, folder_name)\n",
        "        for image_filename in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, image_filename)\n",
        "            try:\n",
        "                image = Image.open(image_path).convert('RGB')\n",
        "                image_array = np.array(image)\n",
        "                images.append(image_array)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Błąd przy wczytywaniu obrazu {image_path}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data'\n",
        "\n",
        "class_labels = {\n",
        "    1: 'moje',\n",
        "    0: 'inne'\n",
        "}\n",
        "\n",
        "images, labels = load_images_and_labels(base_dir, class_labels)\n",
        "\n",
        "print('Wczytano obrazy:', images.shape)\n",
        "print('Wczytano etykiety:', labels.shape)\n",
        "\n",
        "save_dir = '/content/drive/MyDrive/np_arrays'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "np.save(os.path.join(save_dir, 'images.npy'), images)\n",
        "np.save(os.path.join(save_dir, 'labels.npy'), labels)\n",
        "print('Zapisano obrazy i etykiety w:', save_dir)"
      ],
      "metadata": {
        "id": "JTgF1lS7N05N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NswiA9jOHm9p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "path_to_images = '/content/drive/MyDrive/np_arrays/images.npy'\n",
        "path_to_labels = '/content/drive/MyDrive/np_arrays/labels.npy'\n",
        "\n",
        "images = np.load(path_to_images, mmap_mode='r')\n",
        "labels = np.load(path_to_labels, mmap_mode='r')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fw2CFistIeOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=16,\n",
        "    epochs=30,\n",
        "    validation_data=(X_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTdrAnVTIf6X",
        "outputId": "ddab1f59-8336-40b0-ab1f-500f21c65a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "284/284 [==============================] - 43s 124ms/step - loss: 93.4421 - accuracy: 0.9872 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 0.8563 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "284/284 [==============================] - 33s 117ms/step - loss: 231.2897 - accuracy: 0.9905 - val_loss: 0.3838 - val_accuracy: 0.9991\n",
            "Epoch 4/30\n",
            "284/284 [==============================] - 34s 118ms/step - loss: 45.3469 - accuracy: 0.9989 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 14.9754 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "284/284 [==============================] - 33s 117ms/step - loss: 88.0472 - accuracy: 0.9978 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 43.7927 - accuracy: 0.9982 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "284/284 [==============================] - 33s 117ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "284/284 [==============================] - 33s 117ms/step - loss: 1.1721 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "284/284 [==============================] - 33s 117ms/step - loss: 18.9677 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 19.8018 - accuracy: 0.9982 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 12.5164 - accuracy: 0.9991 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "284/284 [==============================] - 33s 117ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "284/284 [==============================] - 33s 117ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "284/284 [==============================] - 33s 115ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "284/284 [==============================] - 33s 115ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "284/284 [==============================] - 33s 115ms/step - loss: 1.4269e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "284/284 [==============================] - 33s 115ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "284/284 [==============================] - 33s 115ms/step - loss: 1.2584 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 176.6842 - accuracy: 0.9974 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 20.9479 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 56.9970 - accuracy: 0.9987 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 10.1078 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 26.6742 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 0.2904 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "284/284 [==============================] - 33s 115ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "284/284 [==============================] - 33s 116ms/step - loss: 5.8041 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=4, batch_size=16, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZmbKyvcJ9jL",
        "outputId": "9d10e4d0-f4c6-47f0-82dc-cce6ff521937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cf81c188610>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test)\n",
        "print('Dokładność wytrenowanego modelu:')\n",
        "print('\\tEtykiety: ', model.metrics_names)\n",
        "print('\\tWartości: ', results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2uengStKAt5",
        "outputId": "b0c73186-6dc8-48f0-ef02-e6e598c64d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 2s 25ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Dokładność wytrenowanego modelu:\n",
            "\tEtykiety:  ['loss', 'accuracy']\n",
            "\tWartości:  [0.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/model/wmapro4.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POxyKsvIKDTS",
        "outputId": "656c093a-4a64-4932-8af6-71b40eb05182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EROTlK6PWEM",
        "outputId": "5bb82826-7bd2-4a53-f350-d0b6656d6374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 34  29  31]\n",
            "  [ 33  29  31]\n",
            "  [ 34  30  32]\n",
            "  ...\n",
            "  [111 109 110]\n",
            "  [112 110 111]\n",
            "  [112 112 112]]\n",
            "\n",
            " [[ 34  30  32]\n",
            "  [ 34  30  32]\n",
            "  [ 34  30  32]\n",
            "  ...\n",
            "  [109 107 108]\n",
            "  [112 110 111]\n",
            "  [112 112 112]]\n",
            "\n",
            " [[ 34  30  32]\n",
            "  [ 34  30  32]\n",
            "  [ 34  30  32]\n",
            "  ...\n",
            "  [109 107 108]\n",
            "  [112 110 111]\n",
            "  [112 112 112]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 19  11  14]\n",
            "  [ 19  11  14]\n",
            "  [ 19  11  14]\n",
            "  ...\n",
            "  [  8   4   4]\n",
            "  [  8   4   4]\n",
            "  [  7   3   3]]\n",
            "\n",
            " [[ 19  11  14]\n",
            "  [ 19  11  14]\n",
            "  [ 19  11  14]\n",
            "  ...\n",
            "  [  8   4   4]\n",
            "  [  8   4   4]\n",
            "  [  7   3   3]]\n",
            "\n",
            " [[ 19  11  14]\n",
            "  [ 19  11  14]\n",
            "  [ 19  11  14]\n",
            "  ...\n",
            "  [  9   5   5]\n",
            "  [  9   5   5]\n",
            "  [  8   4   4]]]\n"
          ]
        }
      ]
    }
  ]
}